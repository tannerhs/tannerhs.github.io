{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMrnXud8XkGAYcQEhUnQhro",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tannerhs/tannerhs.github.io/blob/master/cleaning_pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Z9dc9jSrZmoD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa59f232-5132-448a-a15b-8e0754a8f5a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting translate-toolkit\n",
            "  Downloading translate_toolkit-3.13.3-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: lxml>=4.6.3 in /usr/local/lib/python3.10/dist-packages (from translate-toolkit) (4.9.4)\n",
            "Requirement already satisfied: wcwidth>=0.2.10 in /usr/local/lib/python3.10/dist-packages (from translate-toolkit) (0.2.13)\n",
            "Downloading translate_toolkit-3.13.3-py3-none-any.whl (744 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m744.3/744.3 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: translate-toolkit\n",
            "Successfully installed translate-toolkit-3.13.3\n"
          ]
        }
      ],
      "source": [
        "#read tmx file in\n",
        "!pip install translate-toolkit\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from translate.storage.tmx import tmxfile\n",
        "import translate.storage.tmx\n",
        "from translate.storage.tmx import tmxunit\n",
        "from translate.storage.base import TranslationUnit\n",
        "\n",
        "input_file_1=\"/content/14 320 - Korean - FamilyHistory - Recent.tmx\"\n",
        "input_file_2=\"/content/14 320 - Korean - FamilyHistory - Recent.tmx\"\n",
        "\n",
        "source_language=\"en-us\"\n",
        "target_language=\"kor-KR\"\n",
        "tmx_list=[]\n",
        "\n",
        "with open(input_file_1,\"rb\") as file: #rb is needed, otherwise things freak out if you don't remove the first line with <?xml...\n",
        "  xml=file.read()\n",
        "  tmx=tmxfile(xml,source_language,target_language, encoding=\"utf-8\")\n",
        "for node in tmx.unit_iter():\n",
        "  tmx_list.append([node.source,node.target])"
      ],
      "metadata": {
        "id": "KcrfUPDZFaLa"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_segments(tu):\n",
        "  if((len(tu[0])<5) or (len(tu[1]) <5)):  #remove empty and almost empty segments\n",
        "    return None\n",
        "  #remove segments that are too long, too imbalanced (source or target much longer than other), or too much just numbers\n",
        "  if (tu[0].count(\" \")<2) or (tu[1].count(\" \")<2): #remove units with fewer than 3 words\n",
        "    return None\n",
        "  elif (tu[0].count(\" \")>99) or (tu[0].count(\" \")>99): #remove units with more than 100 words\n",
        "    return None\n",
        "  elif( len(tu[0])/len(tu[1])>=2 or len(tu[1])/len(tu[0])>=2) :\n",
        "    return None\n",
        "  elif ((len(re.findall('[0-9]',tu[0]))/len(tu[0]))>0.4) or (len(re.findall('[0-9]',tu[1]))/len(tu[1])>0.4):\n",
        "    return None  #if too much of string is numbers (more than 40%) just remove the tu\n",
        "  else :\n",
        "    return tu\n",
        "\n",
        "# def remove_hex_characters(tu):\n",
        "#   re.subn(\"&#([a-zA-Z0-9])+ \",\"\",tu[0])\n",
        "\n",
        "\n",
        "\n",
        "def clean(tu):\n",
        "    # alignment and other cleaning\n",
        "    tu[1]=re.subn(r'\\n|\\r|&#xd;?|&#x2028;?|&#x2029;?|&.*;|\\t','', tu[1])[0]\n",
        "    tu[0]=re.subn(r'\\n|\\r|&#xd;?|&#x2028;?|&#x2029;?|&.*;|\\t','', tu[0])[0]\n",
        "    tu[0]=re.subn(r'\\\\n|\\\\r|\\\\t|\\\\:|\\\\f|\\%|\\\\.+|%(.*)%|(<.*>)+|({.*})+','', tu[0])[0]\n",
        "    tu[1]=re.subn(r'\\\\n|\\\\r|\\\\t|\\\\:|\\\\f|\\%|\\\\.+|%(.*)%|(<.*>)+|({.*})+','', tu[1])[0]\n",
        "\n",
        "    # handle uneven {}, [],(),<>\n",
        "\n",
        "    #normalize whitespace-- messes up alignment!\n",
        "    # tu[0]=re.subn(r' +',' ', tu[0])[0]\n",
        "    # tu[1]=re.subn(r' +',' ', tu[1])[0]\n",
        "\n",
        "\n",
        "    # tu[0]=re.subn(r'(\\\\.+)+','',tu[0])[0]\n",
        "    # tu[1]=re.subn(r'(\\\\.+)+','',tu[1])[0]\n",
        "    # tu[0]=re.subn(r'(\\\\.\\s+)+','',tu[0])[0]\n",
        "    # tu[1]=re.subn(r'(\\\\.\\s+)+','',tu[1])[0]\n",
        "    # tu[0]=re.subn(r'(\\\\:)+','',tu[0])[0]\n",
        "    # tu[1]=re.subn(r\"(\\\\:)+\",'',tu[1])[0]\n",
        "    # tu[0]=re.subn(r'\\\\:','',tu[0])[0]\n",
        "    # tu[1]=re.subn(r'\\\\:','',tu[1])[0]\n",
        "\n",
        "    #handle angle brackets\n",
        "    tu[0]=re.subn(r'(<.*>)+','',tu[0])[0]\n",
        "    tu[1]=re.subn(r'(<.*>)+','',tu[1])[0]\n",
        "    tu[0]=re.subn(r'(<)+',\"\", tu[0])[0]\n",
        "    tu[1]=re.subn(r'(<)+',\"\", tu[1])[0]\n",
        "    tu[0]=re.subn(r'(>)+',\"\", tu[0])[0]\n",
        "    tu[1]=re.subn(r'(>)+',\"\", tu[1])[0]\n",
        "\n",
        "    #\n",
        "    # tu[0]=re.subn(r'(#.*\\s+)+',\"\", tu[0])[0]\n",
        "    # tu[1]=re.subn(r'(#.*\\s+)+',\"\", tu[1])[0]\n",
        "    # tu[0]=re.subn(r'(&.*\\s+)+',\"\",tu[0])[0]\n",
        "    # tu[1]=re.subn(r'(&.*\\s+)+',\"\",tu[1])[0]\n",
        "\n",
        "    #normalize quotes\n",
        "    tu[0]=re.subn(r'‘|’','\\'',tu[0])[0]\n",
        "    tu[1]=re.subn(r'‘|’','\\'',tu[1])[0]\n",
        "    tu[0]=re.subn(r'“|”','\\\"',tu[0])[0]\n",
        "    tu[1]=re.subn(r'“|”','\\\"',tu[1])[0]\n",
        "\n",
        "\n",
        "    if remove_segments(tu) is None:\n",
        "      return None\n",
        "\n",
        "    # tu=remove_hex_characters(tu)\n",
        "    return tu"
      ],
      "metadata": {
        "id": "7vF2KrdXN5Pn"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#iterate over all units\n",
        "import re\n",
        "import string\n",
        "\n",
        "def normalize(str):\n",
        "  return re.subn('[%s]' % re.escape(string.punctuation), '', str)[0]\n",
        "\n",
        "\n",
        "# iter=tmx.unit_iter()\n",
        "end_not_reached=True\n",
        "i=0\n",
        "count=0\n",
        "clean_tmx_list=[]\n",
        "clean_tmx_set=set()\n",
        "\n",
        "\n",
        "src_file=open(\"/content/source.txt\",\"w\")\n",
        "tgt_file=open(\"/content/target.txt\", \"w\")\n",
        "\n",
        "while (count<200000) and (i<len(tmx_list)):\n",
        "  tu=tmx_list[i]\n",
        "  tu=clean(tu)  #update tu to be the cleaned version\n",
        "  if (tu is not None):\n",
        "    clean_tmx_list.append([tu[0],tu[1]])\n",
        "    count=count+1\n",
        "  i=i+1\n",
        "\n",
        "\n",
        "for tu in clean_tmx_list:\n",
        "  tu_src_normal = normalize(tu[0])\n",
        "  tu_tgt_normal = normalize(tu[1])\n",
        "  tu_normal_tuple=(tu_src_normal,tu_tgt_normal)\n",
        "  if (tu_src_normal!=tu_tgt_normal) and (tu_normal_tuple not in clean_tmx_set):\n",
        "    clean_tmx_set.add((normalize(tu[0]),normalize(tu[1])))\n",
        "    src_file.write(tu[0]+\"\\n\")\n",
        "    tgt_file.write(tu[1]+\"\\n\")\n",
        "src_file.close()\n",
        "tgt_file.close()"
      ],
      "metadata": {
        "id": "5_m6_UovF57W"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#now write to file\n"
      ],
      "metadata": {
        "id": "yR_RANzqekHo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# type(tmx)\n",
        "\n",
        "# print(tmx.getsourcelanguage())  #todo, incorrect format in tmx, need to convert to iso\n",
        "# print(tmx.gettargetlanguage())\n",
        "# clean_tmx=TMXFile()\n",
        "# clean_tmx=tmxfile(inputfile=None,sourcelanguage=\"en\",targetlanguage=\"kor\")\n",
        "new_tu=tmxunit(source=\"hi\")\n",
        "new_tu.settarget(\"안녕\"*100)\n",
        "# clean_tmx.addunit(new_tu)\n",
        "\n",
        "print(type(new_tu))\n",
        "print(new_tu.target)\n",
        "print(new_tu.source)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NwO2-YcCA-Wg",
        "outputId": "7a1f8793-8b3d-466e-bd94-a804fc426bd4"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'translate.storage.tmx.tmxunit'>\n",
            "안녕안녕안녕안녕안녕안녕안녕안녕안녕안녕안녕안녕안녕안녕안녕안녕안녕안녕안녕안녕안녕안녕안녕안녕안녕안녕안녕안녕안녕안녕안녕안녕안녕안녕안녕안녕안녕안녕안녕안녕안녕안녕안녕안녕안녕안녕안녕안녕안녕안녕안녕안녕안녕안녕안녕안녕안녕안녕안녕안녕안녕안녕안녕안녕안녕안녕안녕안녕안녕안녕안녕안녕안녕안녕안녕안녕안녕안녕안녕안녕안녕안녕안녕안녕안녕안녕안녕안녕안녕안녕안녕안녕안녕안녕안녕안녕안녕안녕안녕안녕\n",
            "hi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test=\"귀하 지역의 상담자(들)\\:\"\n",
        "re.subn(r'\\\\:','',test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_GIhI1zoaW31",
        "outputId": "132f3d55-0802-4ed9-8113-3906a0ce0a1d"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('귀하 지역의 상담자(들)', 1)"
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test=map(tuple,[[\"a\",\"b\"],[\"c\",\"d\"],[\"a\",\"b\"]])"
      ],
      "metadata": {
        "id": "VkEj6F2Kffb9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}